# vis_compare.py
"""
Visualize history + GT vs model prediction for a chosen (recording .pt, vehicleId, start frame).

- history + ground truth future : gray
- predicted future trajectory   : blue

Example:
  python3 vis_compare.py \
    --config configs/baseline.yaml \
    --ckpt ckpts/best.pt \
    --pt data/highd_59.pt \
    --vehicle_id 42 \
    --t0_frame 1200 \
    --out vis/rec59_vid42_f1200.png

Notes
- This script follows the same model loading style as src/eval.py and uses the same stats loader in src/utils.py.
- It rebuilds x_ego/x_nb from the stored tensors inside the .pt file generated by raw_to_npz.py / npz_to_pt.py.
"""

from __future__ import annotations

import argparse
from pathlib import Path
from typing import Dict, Any, Optional, Tuple

import yaml
import numpy as np
import torch
import matplotlib.pyplot as plt
import sys 

TP_BASELINE_DIR = Path(__file__).resolve().parents[1]
sys.path.insert(0, str(TP_BASELINE_DIR))

from src.utils import load_stats_npz, build_model, set_seed


def _resolve_path(base: Path, p: str) -> Path:
    pp = Path(p)
    return pp if pp.is_absolute() else (base / pp).resolve()


def _as_torch(x) -> torch.Tensor:
    if isinstance(x, torch.Tensor):
        return x
    return torch.from_numpy(x)


def build_inputs_from_pt(
    pt_dict: Dict[str, torch.Tensor],
    idx: int,
    stats: Dict[str, torch.Tensor],
    *,
    use_neighbors: bool = True,
    use_context: bool = True,
    use_safety: bool = True,
    use_preceding: bool = True,
    use_lane: bool = True,
    use_static: bool = True,
) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:
    """
    Returns:
      x_ego  : (1,T,ego_dim) normalized
      x_nb   : (1,T,S,nb_dim) normalized (S=8)
      nb_mask: (1,T,S) bool
      y_abs  : (1,Tf,2) absolute
      x_last_abs: (1,2) absolute (last point of history)
    """
    x_hist = pt_dict["x_hist"][idx]      # (T,6) absolute (x,y, vx, vy, ax, ay) in this pipeline
    y_fut  = pt_dict["y_fut"][idx]       # (Tf,2) absolute
    T = x_hist.shape[0]

    # ---- ego features ----
    feats = [x_hist]  # (T,6)
    if use_context and "tv_context" in pt_dict:
        feats.append(pt_dict["tv_context"][idx])  # (T,2)
    if use_safety and "tv_safety" in pt_dict:
        feats.append(pt_dict["tv_safety"][idx])   # (T,3)
    if use_preceding and "tv_preceding" in pt_dict:
        feats.append(pt_dict["tv_preceding"][idx])  # (T,1)
    if use_lane and "tv_lane" in pt_dict:
        lane = pt_dict["tv_lane"][idx].to(torch.float32).unsqueeze(-1)  # (T,1)
        feats.append(lane)
    if use_static and "tv_static" in pt_dict:
        tvs = pt_dict["tv_static"][idx].to(torch.float32).view(1, -1).repeat(T, 1)  # (T,3)
        feats.append(tvs)

    x_ego = torch.cat(feats, dim=-1).to(torch.float32)  # (T,ego_dim)
    ego_mean = stats["ego_mean"].to(x_ego.device).view(1, -1)
    ego_std  = stats["ego_std"].to(x_ego.device).view(1, -1).clamp_min(1e-6)
    if ego_mean.shape[-1] != x_ego.shape[-1]:
        raise ValueError(
            f"ego_dim mismatch: x_ego has {x_ego.shape[-1]} dims but stats has {ego_mean.shape[-1]} dims. "
            "Check feature flags (use_context/use_safety/...) to match the stats used in training."
        )
    x_ego = (x_ego - ego_mean) / ego_std
    x_ego = x_ego.unsqueeze(0)  # (1,T,ego_dim)

    # ---- neighbors ----
    if use_neighbors:
        nb_hist = pt_dict["nb_hist"][idx]   # (T,8,6) relative-to-ego (nb_feat - ego_feat)
        nb_mask = pt_dict["nb_mask"][idx]   # (T,8) bool
        nb_feats = [nb_hist.to(torch.float32)]
        if use_static and "nb_static" in pt_dict:
            nbs = pt_dict["nb_static"][idx].to(torch.float32).view(1, 8, -1).repeat(T, 1, 1)  # (T,8,3)
            nb_feats.append(nbs)
        x_nb = torch.cat(nb_feats, dim=-1)  # (T,8,nb_dim)

        nb_mean = stats["nb_mean"].to(x_nb.device).view(1, 1, -1)
        nb_std  = stats["nb_std"].to(x_nb.device).view(1, 1, -1).clamp_min(1e-6)
        if nb_mean.shape[-1] != x_nb.shape[-1]:
            raise ValueError(
                f"nb_dim mismatch: x_nb has {x_nb.shape[-1]} dims but stats has {nb_mean.shape[-1]} dims. "
                "Check feature flags (use_static/use_neighbors) to match training."
            )
        x_nb = (x_nb - nb_mean) / nb_std

        x_nb = x_nb.unsqueeze(0)            # (1,T,8,nb_dim)
        nb_mask = nb_mask.unsqueeze(0)      # (1,T,8)
    else:
        # keep shapes consistent for models expecting them
        x_nb = torch.zeros((1, x_hist.shape[0], 8, stats["nb_mean"].numel()), dtype=torch.float32)
        nb_mask = torch.zeros((1, x_hist.shape[0], 8), dtype=torch.bool)

    # ---- targets / last abs ----
    y_abs = y_fut.to(torch.float32).unsqueeze(0)          # (1,Tf,2)
    x_last_abs = x_hist[-1, 0:2].to(torch.float32).unsqueeze(0)  # (1,2)

    return x_ego, x_nb, nb_mask, y_abs, x_last_abs


def pick_sample_index(pt_dict: Dict[str, torch.Tensor], vehicle_id: int, t0_frame: int) -> int:
    track = pt_dict["trackId"].cpu().numpy()
    t0 = pt_dict["t0_frame"].cpu().numpy()
    mask = (track == vehicle_id) & (t0 == t0_frame)
    idxs = np.where(mask)[0]
    if len(idxs) == 0:
        # helpful error: show available t0 frames for this vehicle
        cand = np.where(track == vehicle_id)[0]
        if len(cand) == 0:
            raise ValueError(f"vehicle_id={vehicle_id} not found in this .pt file.")
        t0s = np.unique(t0[cand])
        # show nearest 10
        nearest = t0s[np.argsort(np.abs(t0s - t0_frame))][:10]
        raise ValueError(
            f"(vehicle_id={vehicle_id}, t0_frame={t0_frame}) not found.\n"
            f"Nearest t0_frame candidates for this vehicle: {nearest.tolist()}"
        )
    return int(idxs[0])


def plot_trajs(history_xy: np.ndarray, gt_future_xy: np.ndarray, pred_future_xy: np.ndarray, title: str):
    """
    history_xy: (T,2)
    gt_future_xy: (Tf,2)
    pred_future_xy: (Tf,2)
    """
    # concat history + gt future for the "gray" polyline
    gt_full = np.concatenate([history_xy, gt_future_xy], axis=0)  # (T+Tf,2)

    plt.figure(figsize=(6, 6))
    plt.plot(gt_full[:, 0], gt_full[:, 1], linewidth=2.5, alpha=0.9)  # default color (we'll set via kwargs below)
    # recolor explicitly for clarity
    plt.gca().lines[-1].set_color("gray")

    plt.plot(pred_future_xy[:, 0], pred_future_xy[:, 1], linewidth=2.5, alpha=0.95)
    plt.gca().lines[-1].set_color("tab:blue")

    # start/end markers
    plt.scatter(history_xy[0, 0], history_xy[0, 1], s=25, c="gray", marker="o", alpha=0.9, label="start")
    plt.scatter(gt_future_xy[-1, 0], gt_future_xy[-1, 1], s=35, c="gray", marker="x", alpha=0.9, label="GT end")
    plt.scatter(pred_future_xy[-1, 0], pred_future_xy[-1, 1], s=35, c="tab:blue", marker="x", alpha=0.9, label="Pred end")

    plt.axis("equal")
    plt.grid(True, alpha=0.25)
    plt.title(title)
    plt.legend(loc="best")
    plt.tight_layout()


@torch.no_grad()
def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--config", type=str, required=True, help="same yaml used for training/eval")
    ap.add_argument("--ckpt", type=str, required=True, help="checkpoint path")
    ap.add_argument("--pt", type=str, required=True, help="path to a single highd_XX.pt")
    ap.add_argument("--vehicle_id", type=int, required=True)
    ap.add_argument("--t0_frame", type=int, required=True)
    ap.add_argument("--out", type=str, default=None, help="png path (optional)")
    ap.add_argument("--show", action="store_true", help="show interactive window")
    args = ap.parse_args()

    cfg_path = Path(args.config).resolve()
    cfg_dir = cfg_path.parent
    cfg: Dict[str, Any] = yaml.safe_load(cfg_path.read_text())

    set_seed(int(cfg.get("train", {}).get("seed", 42)))

    want_cuda = (cfg.get("train", {}).get("device", "cuda") == "cuda")
    device = torch.device("cuda" if (want_cuda and torch.cuda.is_available()) else "cpu")

    # feature flags must match what you trained with
    feat = cfg.get("features", {})
    flags = dict(
        use_neighbors=feat.get("use_neighbors", True),
        use_context=feat.get("use_context", True),
        use_safety=feat.get("use_safety", True),
        use_preceding=feat.get("use_preceding", True),
        use_lane=feat.get("use_lane", True),
        use_static=feat.get("use_static", True),
    )

    # stats path from config
    stats_path = _resolve_path(cfg_dir, cfg["data"]["stats_path"])
    if not stats_path.exists():
        raise FileNotFoundError(f"Stats file not found: {stats_path}")
    stats = load_stats_npz(str(stats_path))

    # load model + ckpt
    model = build_model(cfg).to(device)
    ckpt = torch.load(str(Path(args.ckpt).resolve()), map_location="cpu", weights_only=False)
    state = ckpt["model"] if isinstance(ckpt, dict) and "model" in ckpt else ckpt
    model.load_state_dict(state, strict=True)
    model.eval()

    # Stage1/2 flag: delta or absolute
    predict_delta = bool(cfg.get("model", {}).get("predict_delta", False))

    # load pt
    pt_dict = torch.load(str(Path(args.pt).resolve()), map_location="cpu", weights_only=False)

    idx = pick_sample_index(pt_dict, args.vehicle_id, args.t0_frame)

    x_ego, x_nb, nb_mask, y_abs, x_last_abs = build_inputs_from_pt(
        pt_dict, idx, stats, **flags
    )

    x_ego = x_ego.to(device)
    x_nb = x_nb.to(device)
    nb_mask = nb_mask.to(device)
    y_abs = y_abs.to(device)
    x_last_abs = x_last_abs.to(device)

    # forward
    pred = model(x_ego, x_nb, nb_mask)
    if isinstance(pred, (tuple, list)):
        pred = pred[0]

    # handle multi/single modal + delta/abs
    if pred.dim() == 4:
        # (B,M,Tf,2) -> pick best by minADE in ABS space (same logic as eval.py)
        B, M, Tf, D = pred.shape
        if predict_delta:
            pred_abs_all = torch.cumsum(pred, dim=2) + x_last_abs[:, None, None, :]
        else:
            pred_abs_all = pred
        err = torch.norm(pred_abs_all - y_abs[:, None, :, :], dim=-1)  # (B,M,Tf)
        ade_bm = err.mean(dim=-1)  # (B,M)
        best_idx = ade_bm.argmin(dim=1)
        best_pred_abs = pred_abs_all[torch.arange(B, device=device), best_idx]  # (B,Tf,2)
        pred_abs = best_pred_abs
    else:
        # (B,Tf,2)
        if predict_delta:
            pred_abs = torch.cumsum(pred, dim=1) + x_last_abs[:, None, :]
        else:
            pred_abs = pred

    # prepare plot arrays in ABS space
    history_xy = pt_dict["x_hist"][idx][:, 0:2].cpu().numpy()
    gt_future_xy = pt_dict["y_fut"][idx].cpu().numpy()
    pred_future_xy = pred_abs[0].detach().cpu().numpy()

    rec_id = int(pt_dict["recordingId"][idx].item()) if "recordingId" in pt_dict else -1
    title = f"rec={rec_id} vehicle={args.vehicle_id} t0={args.t0_frame}"

    plot_trajs(history_xy, gt_future_xy, pred_future_xy, title=title)

    if args.out is not None:
        outp = Path(args.out)
        outp.parent.mkdir(parents=True, exist_ok=True)
        plt.savefig(str(outp), dpi=150)
        print(f"saved: {outp}")

    if args.show:
        plt.show()
    else:
        plt.close()


if __name__ == "__main__":
    main()
